---
title: "Differentiation exercises"
author: "Daniel Kaplan"
subject: "derivatives"
---

```{r include=FALSE}
library(mosaic)
library(mosaicCalc)
```

# Exercise 1

In 2006, and again in 2012, the New York *Times* published mathematical models of celebrity divorce.  The purpose of the models was to address the pressing social need of predicting how long celebrity marriages will last.

Like any prediction model, the marriage duration prediction is based on information that is available at the time the prediction is made.  Two of the variables in the models reflect news coverage about the celebrities. 

- NYT: the number of search results since 1990 in the New York *Times* archive.
- ENQ: the number of search results since 1990 in the  *National Enquirer* archive.

Note, the *Times* is considered by many the newspaper of record in the US, whereas the *Enquirer* has a more sensationalist style.

Other variables describe the couple themselves:

- $A_h$: Age, in years, of the husband.
- $A_w$: Age, in years, of the wife.
- Sc: Number of photos in the top five Google Image hits, showing the wife scantily clad.
- Md: Number of months the couple dated before marriage.
- $T$ Time, in years after the marriage, at which the prediction is to be made.

Here is a 2012 snapshot of the data on these model inputs:

![](/images/divorce-data.png)

The formula given for the percentage chance $P$  that the two celebrities will still be married after $T$ years is:
$$ P = 50  \sqrt[15]{\frac{NYT}{ENQ} \frac{(A_h + A_w)}{(Sc + 5)} Md \left[ \frac{Md}{(Md+2)} \right]^{T^2} }$$

Or, in R:
```{r }
P = makeFun( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ 
  T | NYT | ENQ | Ah | Aw | Sc | Md )
```
 

This is a genuinely complicated formula, and it's easy to get it wrong when translating from mathematical notation to R or just in typing the R statement.   To make sure you have things right, apply your function to one or more of the data points given by the *Times* and make sure that you are getting the right output.  Here, for instance, is the function applied to the values for Chelsea Clinton and Marc Mezvinsky.  Note that they match the published predicted values.  Yours should too.

```{r }
P(T=1,NYT=618,ENQ=26,Ah=33,Aw=30,Sc=0,Md=50)
P(T=5,NYT=618,ENQ=26,Ah=33,Aw=30,Sc=0,Md=50)
P(T=15,NYT=618,ENQ=26,Ah=33,Aw=30,Sc=0,Md=50)
```
 

Your task is to assess whether the model is reasonable.  By "reasonable," we do not mean "correct"; there's no way to know what will happen to these couples.  Rather, you should see whether the model is in accord with your intuitive understanding of the factors that might lead to a divorce.

The equation itself is basically impenetrable, but you can ask some simple questions of the model.  Here are a few:

Holding all the other variables constant (at, say, the level for some couple of interest to you), what do you think will happen to the probability of staying married for at least 5 years:

#.  As NYT increases, probability of staying married 
  {increases}{increases,decreases,stays the same}
#.  As ENQ increases, probability of staying married 
  {increases}{increases,decreases,stays the same}
#.  As $A_h$ increases, probability of staying married 
  {increases}{increases,decreases,stays the same}
#.  As $A_w$ increases, probability of staying married 
  {increases}{increases,decreases,stays the same}
#.  As $Sc$ increases, probability of staying married 
  {increases}{increases,decreases,stays the same}
#.  As $Md$ increases, probability of staying married 
  {increases}{increases,decreases,stays the same}
#.  As $T$ increases, probability of staying married 
  {increases}{increases,decreases,stays the same}


Now, having answered the above according to your intuition, see what the model says.  Calculate the appropriate partial derivative, evaluating it at the input values for a couple of your choice.  Mark down on the above whether the value of the derivative is consistent with your intuition.  Do this for all of the variables in the formula.

To help you out, here is an R statement for the partial with respect
to $A_h$:
```{r }
dPdAh = D( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ Ah )
```
 

With a very slight modification of this statement, you can construct the partial derivatives with respect to the other variables.  Evaluate the derivative function for a celebrity couple of your choice and see whether the sign of the resulting number is consistent with your intuition.

ANSWER
Setting up the derivatives:
```{r }
dPdAh = D( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ Ah )
dPdAw = D( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ Aw )
dPdNYT = D( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ NYT )
dPdENQ = D( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ ENQ )
dPdSc = D( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ Sc )
dPdMd = D( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ Md )
```
 

And evaluating them for Jennifer Lopez and Ojani Noi
```{r}
P(NYT=1266,ENQ=175,Ah=25,Aw=27,Sc=4,Md=6,T=5)
dPdNYT(NYT=1266,ENQ=175,Ah=25,Aw=27,Sc=4,Md=6,T=5)
dPdENQ(NYT=1266,ENQ=175,Ah=25,Aw=27,Sc=4,Md=6,T=5)
dPdAh(NYT=1266,ENQ=175,Ah=25,Aw=27,Sc=4,Md=6,T=5)
dPdAw(NYT=1266,ENQ=175,Ah=25,Aw=27,Sc=4,Md=6,T=5)
dPdSc(NYT=1266,ENQ=175,Ah=25,Aw=27,Sc=4,Md=6,T=5)
dPdMd(NYT=1266,ENQ=175,Ah=25,Aw=27,Sc=4,Md=6,T=5)
```
 
END of ANSWER

The magnitude of the derivative gives an indication of the importance of the variable.  Of course, what matters is not so much the *rate*, but the change in probability, which involves multiplying the rate by the change in the input.  For example, you can see that the Sc variable ranges from 0 to 5, so a change of four points covers the whole range of the scale.  Multiplying the derivative with respect to Sc by such a difference gives an idea of how much the output will change from, say, Kate Middleton  to Jennifer Lopez.

Consider the range of each of the input variables in the data below. Multiply this difference by the corresponding partial derivative to get a sense for how much that variable contributes to the variation from couple to couple in the probabilities of still being married.

#.  Which variable or variables seem to be the most strongly associated with the output of the function?

Now, onto second derivatives.  Here's an R statement to construct the mixed partial derivative with respect to Sc and Md.

```{r }
ScMd = D( 
  50*( (NYT/ENQ)*((Ah+Aw)/(Sc+5))*Md*
      (Md/(Md+2))^(T^2))^(1/15) ~ Sc|Md )
```
 
Here's the value of this derivative for Kate Middleton and Prince William:
```{r }
ScMd(NYT=258,ENQ=44,Ah=29,Aw=29,Sc=0,Md=120,T=5)
```
 
As you've already seen, the model holds Sc to be negative in its influence on the probability to stay married.  This mixed partial derivative is negative, suggesting that scantily-clad photos are even more negative prognosticators the longer the couple dated (Md).   That is, for long-dating couples, Sc is even worse in its effect: an interaction in the model.

#.  Pick another pair of variables for and find the mixed partial derivative with respect to these.  Try to interpret the result  in everyday language suitable for publication in the *National Enquirer*.

# Exercise 2

You are walking along the red path from A to I.  At each of the marked points, say whether you are going uphill, downhill, or level.  (Use "level" is the slope is much smaller than at most of the other points.)

```{r walkplot,echo=FALSE}
f=rfun( ~x|y, seed=672)
data <- data_frame(
  t = seq(0:10),
  x = c(-2,-1,0,1,1.5,1.3,1.0,0,-.5,-1.2,-1.9 ),
  y = c(0,.75,1,1.2,.5,0,-.5,-1.0,-1.3,-1.5,-1.9)
)
tpts = seq(0,10,length=500)
px = spliner(x~t, data=data)
py = spliner(y~t, data=data)
plotFun(f(u,v)~u + v, ulim=range(-2,2), vlim=range(-2,2) ) 
ladd(llines(x=px(tpts),y=py(tpts),col="red",lwd=3))
ladd( ltext(x=px(1:9),y=py(1:9),c("A","B","C","D","E","F","G","H","I")))
```
 
A. {Level}{Uphill,Downhill,Level}    
B.  {Downhill}{Uphill,Downhill,Level}    
C.  {Downhill}{Uphill,Downhill,Level}     
D.  {Level}{Uphill,Downhill,Level}     
E.  {Uphill}{Uphill,Downhill,Level}     
F.  {Uphill}{Uphill,Downhill,Level}     
G.  {Uphill}{Uphill,Downhill,Level}     
H.  {Uphill}{Uphill,Downhill,Level}     
I.  {Uphill}{Uphill,Downhill,Level}     


# Exercise 3

Here's a contour plot of a function of two variables:

```{r uvplot3,echo=FALSE}
f <- rfun( ~ x | y, seed=672)
print(plotFun(f(u,v)~  u +  v, ulim=range(-2,2), vlim=range(-2,2) ) )
ladd( ltext(x=c(-1.2,0,1.2,-1.2,0,1.2,-1.2,0,1.2),y=c(1,1,1,0,0,0,-1,-1,-1),c("a","b","c","d","e","f","g","h","i")))
```
 

At each of the marked points, say whether the partial derivative is positive, negative, or zero.  (NOTE: It's hard to say from a contour graph like this when something is exactly zero.  And if it's not exactly zero, then it must be either positive or negative.  Here, use "zero" to mean "much smaller in magnitude than at most of the other points.)

a. $\partial f/ \partial u$ {neg}{pos,zero,neg}  $\partial f/ \partial v$ {zero}{pos,zero,neg} <!--A-->

#.  $\partial f/ \partial u$ {neg}{pos,zero,neg} $\partial f/ \partial v$ {zero}{pos,zero,neg} <!--B-->

#.  $\partial f/ \partial u$ {pos}{pos,zero,neg}  $\partial f/ \partial v$ {neg}{pos,zero,neg} <!--C-->

#.  $\partial f/ \partial u$ {neg}{pos,zero,neg} $\partial f/ \partial v$ {neg}{pos,zero,neg} <!--D-->

#.  $\partial f/ \partial u$ {pos}{pos,zero,neg} $\partial f/ \partial v$ {neg}{pos,zero,neg} <!--E-->

#.  $\partial f/ \partial u$ {pos}{pos,zero,neg} $\partial f/ \partial v$ {neg}{pos,zero,neg} <!--F-->

#.  $\partial f/ \partial u$ {zero}{pos,zero,neg} $\partial f/ \partial v$ {neg}{pos,zero,neg} <!--G-->

#.  $\partial f/ \partial u$ {neg}{pos,zero,neg} $\partial f/ \partial v$ {neg}{pos,zero,neg} <!--H-->

#.  $\partial f/ \partial u$ {pos}{pos,zero,neg} $\partial f/ \partial v$ \SelectSetHoriz{neg}{pos,zero,neg} <!--I-->

# Exercise 4

Here's a contour plot of a function of two variables:

```{r uvplot2,echo=FALSE}
f=rfun( ~x|y, seed=6724)
print(plotFun(f(u,v)~ u + v, ulim=range(-2,2), vlim=range(-2,2) ) )
ladd( ltext(x=c(-1.2,0,1.2,-1.2,0,1.2,-1.2,0,1.2),y=c(1,1,1,0,0,0,-1,-1,-1),c("A","B","C","D","E","F","G","H","I")))
```
 


The "gradient" vector points in the steepest **uphill** direction.

At each of the marked points, say which direction (approximately) the gradient points in.  (Directions are given using north-east-south-west compass points.  Assume that north is up and east is to the right.)

#.    \SelectSetHoriz{NW}{SE,SW,NW,NE} %A
#.    \SelectSetHoriz{E}{S,W,N,E}
#.    \SelectSetHoriz{NE}{SE,SW,NW,NE}
#.    \SelectSetHoriz{NW}{SE,SW,NW,NE} %D
#.    \SelectSetHoriz{NW}{SE,SW,NW,NE}
#.    \SelectSetHoriz{NE}{SE,SW,NW,NE}
#.    \SelectSetHoriz{N}{S,W,N,E} %G
#.    \SelectSetHoriz{N}{S,W,N,E}
#.    \SelectSetHoriz{NE}{SE,SW,NW,NE}



# Exercise 5


```{r uvplot1,echo=FALSE}
f=rfun( ~x|y, seed=1324)
print(plotFun(f(u,v)~ u + v, ulim=range(-2,2), vlim=range(-2,2), filled=FALSE ) )
ladd( ltext(x=c(-1.2,0,-1.2,1.2),y=c(1,1.3,-.5,-1),c("A","B","C","D")))
```
 

At each of the 4 points A to D, draw the gradient vector as an arrow with its root at the point.  You should be able to get the direction right.  As for the length of the arrow, make it relatively longer or shorter depending on the "steepness" of the function at the point.

# Exercise 6: Cobb-Douglas

The "Cobb-Douglas production function" is a simple mathematical model how labor $L$  and capital $K$ combine to produce output $P$. It is
$$ P(L,K) = A K^\alpha L^{1-\alpha} .$$

For simplicity, imagine that capital and labor are both measured in dollars per year --- the amount that the labor force is paid in a year and the amount that one could rent a factory for a year. 

a. If production $P(L,K)$ is also measured in dollars per year   (say, the value of the factory output), what is the dimension of the   constant $A$?
  
#.  According to the model, what happens to production if both $K$ and $L$ are increased by   a factor constant factor $\beta$?  (Hint: Substitute in $K \rightarrow \beta K$ and $L \rightarrow \beta L$ and simplify.)

#.   Consider a particular factory with $A=2.5$ and $\alpha=0.33$. In R, implement the function $P(K,L)$.  Use your function to compute   the production of the factory for $K=10$ and $L=20$.  Confirm that   you get $P(K=10,L=20) = 39.78$.
  
<!-- begin ANSWER -->
```{r }
P = makeFun( A*(K^a)*(L^(1-a)) ~ K|L, 
                  A=2.5, a=0.33 ) 
P(K=10,L=20)
```
 
<!-- end ANSWER -->

#.  Of course, a factory that rents for $10/yr and where the labor   costs $20/yr is silly.  Calculate the value $P(K,L)$ when $K$ is $10 million/yr and $L$ is $20 million/yr.


We'll stick with numbers like $K=10$ and $L=20$ to keep things easy to read, but feel free to interpret them as "millions of dollars." 

Congratuations!  Based on your ability to use the Cobb-Douglas model, you've been promoted to manager of the factory.  One of your jobs is to decide how to balance expenditures on capital and labor in order to raise productivity.  

One basic question is what happens when you raise either capital or labor, holding the other one constant.  Using appropriate partial derivatives evaluated at $K=10$, $L=20$, calculate:

a. The rate at which an increase in spending on labor will increase productivity.
  
<!-- begin ANSWER -->
```{r }
dPdL = D( P(K=K,L=L)~L )
dPdL(K=10,L=20)
```
 
<!-- end ANSWER -->
  
#. The rate at which an increase in spending on capital will   increase productivity.
  
<!-- begin ANSWER -->
```{r }
dPdK = D( P(K=K,L=L)~K )
dPdK(K=10,L=20)
```
 
<!-- end ANSWER -->

#. Based on the above, if you had to choose between spending on   capital or labor, and your goal is to increase productivity as much   as possible, which would you spend on, capital or labor?



Your economist friend tells you to watch out for "diminishing marginal returns."  This means that, as you increase spending on either labor or capital, the rate of increase in production tends to diminish.  You'll still get increased production as you increase spending, but it won't increase as fast at high levels of expense as at low levels.


a. Compute the partial derivative of production with respect to   labor at a higher level of labor, say $L=21$, but holding $K=10$.   How does the value of the derivative at $L=21$ compare to that at   $L=20$?  Is this consistent with the idea of "diminishing marginal   returns" for labor?

<!-- begin ANSWER -->
The rate of production increase, when capital spending is increased,
goes down at $L=21$ compared to $L=21$ (holding $K=10$).
```{r }
dPdL(K=10,L=21) - dPdL(K=10,L=20)
```
 
<!-- end ANSWER -->
  
  
#.   Do the same for the partial derivative of production with   respect to capital, evaluated at $L=20$ and $K=11$.  How does the   value of the derivative at $K=11$ compare to that at $K=10$.  Is   this consistent with the idea of "diminishing marginal returns"   for capital?

<!-- begin ANSWER -->
The rate of production increase, when capital spending is increased,
goes down at $K=11$ compared to $K=10$ (holding $L=20$).
```{r }
dPdK(K=11,L=20) - dPdK(K=10,L=20)
```
 
<!-- end ANSWER -->
  
  
#.   Use an appropriate partial second derivative to find the rate of   diminishing partial returns for labor at $L=20$ and $K=10$.  Show   that it's consistent with the difference you got in Part (a).

<!-- begin ANSWER -->
```{r }
dPdL2 = D( P(K=K,L=L)~L|L )
dPdL2(K=10,L=20)
```
 

The second derivative is negative, indicating diminishing marginal returns.  Notice that the magnitude of the second derivative, multiplied by the change by 1 in $L$ from $L=20 \rightarrow 21$, is roughly the same as the answer in (a).

<!-- end ANSWER -->

#.   Use an appropriate partial second derivative to find the rate of   diminishing partial returns for capital at $L=20$ and $K=10$.  Show   that it's consistent with the difference you got in Part (b).

<!-- begin ANSWER -->
```{r }
dPdK2 = D( P(K=K,L=L)~K|K )
dPdK2(K=10,L=20)
```
 
The second derivative is negative, indicating diminishing marginal returns.  Notice that the magnitude of the second derivative, multiplied by the change by 1 in $L$ from $L=20 \rightarrow 21$, is roughly the same as the answer in (b).

<!-- end ANSWER -->

#.  You might think of the rate of increase in production with   respect to labor as the ``value rate" of labor.  Similarly, the rate of   increase in production with respect to capital is the value of   capital.   Due to diminishing marginal returns, an increase in labor   spending, holding capital constant, decreases the value rate of   labor.  Similarly, an increase in capital spending holding labor   spending constant decreases the value rate of capital. 
  
But what happens to the value of labor when capital spending is   increased?  You can answer this by comparing the value rate of labor,   $\frac{\partial  P}{\partial L}$, at two different capital spending   levels, say   $(K=10,L=20)$ and $(K=11,L=20)$.  Notice that even though you're   looking at the rate with respect to labor, you're changing the   expenditure on capital.
  
#. Compare $\frac{\partial P}{\partial L}$ at slightly different     values of $K$, holding $L$ constant at 20.  Does the value rate of     labor increase or decrease with spending on capital?     

<!-- begin ANSWER -->  
```{r }
dPdL(K=11,L=20) - dPdL(K=10,L=20)
```
 
This is a positive change, meaning that increasing spending on capital increases the value of labor.
<!-- end ANSWER -->
    
#. Similarly, compare $\frac{\partial P}{\partial K}$ at slightly different     values of $L$, holding $K$ constant at 20.  Does the value rate of     labor increase or decrease with spending on capital?     

<!-- begin ANSWER -->  
```{r }
dPdK(K=10,L=21) - dPdK(K=10,L=20)
```
 
Similarly, increasing spending on labor, increases the value of capital.  Note that the numerical values are *almost* the same. When we move from a finite difference ($L=20 \rightarrow 21$) to an infinitesimal, the numbers will be exactly the same.

<!-- end ANSWER -->    
    
#.   Finally, construct and evaluate the mixed partial derivative,     $\frac{\partial^2 P}{\partial L \partial K}$ at $K=10, L=20$.     Compare this to the results you got for the  way $\frac{\partial     P}{\partial K}$ changes with increasing $L$ and the way    $\frac{\partial P}{\partial L}$ changes with increasing $K$. 
    
  
<!-- begin ANSWER -->  
```{r }
d2PdLdK = D( P(K=K,L=L)~K|L )
d2PdKdL = D( P(K=K,L=L)~L|K )
d2PdLdK(K=10,L=20) 
d2PdKdL(K=10,L=20) 
```
 
<!-- end ANSWER -->  

The two mixed partials are exactly the same.  As you can see, they are also very close to the rate for the finite difference.    

# Exercise 7

The graph shows actual data (the $+$ and $\times$ marks) of annual phosphate production in the US as well as the cumulative amount produced.  The smooth curves show a model fitted to the data.


![](/images/phosphate-production.png)

Source of graph: <http://www.theoildrum.com/node/4624>

#. According to the model, what's going to happen to phosphate production over the next few decades.


#. Using the model, estimate the parameters "mean" and "standard deviation" for cumulative phosphate production. 

#. Explain why there are two curves, even though there's just one model.

#. EXTRA CREDIT: Comment on how well the data matches the model for   the purposes of using the model for prediction.

# Exercise 8

Here is a second-order polynomial in two variables, $x$ and $y$:
$$ p(x,y) = a_0 + a_1 x + a_2 y + a_3 x y + a_4 x^2 + a_5 y^2  .$$

Write down each of the following derivatives:

a.  ${\partial p}/{\partial x}$

#. ${\partial p}/{\partial y}$

#. ${\partial^2 p}/{\partial x^2}$

#. ${\partial^2 p}/{\partial y^2}$

#. ${\partial^2 p}/{\partial x \partial y}$ (First w.r.t. $y$, then w.r.t. $x$)

#. ${\partial^2 p}/{\partial x \partial y}$ (First w.r.t. $x$, then w.r.t. $y$)

#.  Which of the above derivatives relates most clearly and plainly to the interaction term?

# Exercise 9: Keep your kayak upright

Kayaks are small, light boats that are relatively narrow.  They are fast, but tippy.  

```{r echo=FALSE, fig.cap="A NordKapp LV at sea. [Photo source]( http://seakayakphoto.blogspot.com/2007/01/valley-nordkapp-lv-test.html)" }
knitr::include_graphics("/images/nordkapp-photo.png")
```

The graph provides stability information about the NordKapp LV sea kayak.  

```{r echo=FALSE}
knitr::include_graphics("/images/kayak-righting2.png")
```

There are four variables involved in the
graph:

- Degrees of Heel, $H$.  This is the angle at which the kayak is tipped.  0 means sitting level on the water.  90 is turned completely on its side.
- Cargo load, $L$ in pounds.  
- Paddler weight $W$.  Cargo sits low inside the boat, whereas the paddler sits relatively higher. 
- Righting moment $M$ in foot pounds.  The higher the righting moment, the greater the tendency of the kayak to return to a level position (that is $H = 0$) on the water.


The righting moment is an important feature of a kayak.  If the kayak is tipped at an angle of heel that gives zero righting moment, there is no restoring force and the kayak can easily be tipped more.  The angle at which the righting moment is a maximum can be considered the tipping point --- if there is a tipping force  that pushes the kayak to heel past this angle, the kayak will tip even further and capsize. 

Your job: 

a. Build a second-order polynomial formula that will model the data presented about the stability of the kayak.  Use your formula to predict a cargo load $L$ such that the kayak will produce a righting moment $M=30$ foot pounds at an angle of $H=30$ degrees.  
#. Using your model, make a graph in the same style as that shown above.  Comment on what aspects of the kayak behavior your model gets right and what it's missing.


Some suggestions:

* Read some $H, L, W, M$ values from the graph.  Each point on one of the curves corresponds to a particular value of $H, L, W$, and $M$.  Store these data in a spreadsheet.
* Decide which model terms in a second-order polynomial of $M( L, H, W )$ you should include.
* Use `project` to fit the polynomial to the data.

# Exercise 10

In this activity, you're going to explore the selection of terms in polynomial approximations.  

The background:

a. Polynomials provide a general-purpose approach to modeling functional relationships.
b. In practice, polynomials of first- or second-order are used to model simple relationships.  Here are first- and second-order polynomials in two variables.
    - First order $p_1(x,y) = a_0 + a_1 x + a_2 y + a_3 x y$
    - Second order $p_2(x,y) = b_0 + b_1 x + b_2 y +  b_3 x y + b_4 x^2 + b_5 y^2$
#. The "goodness of fit" of an approximation can be measured by the residuals: the difference between the actual relationship and the approximation.  The "RMS error" (root mean square error) reflects the average magnitude of the residuals. 
#. The more polynomial terms, the better will be the approximation in an RMS sense.
#. HOWEVER, there are reasons to want to leave out polynomials terms, even though more terms will give a better RMS measure.
    * The philosophical notion of "parsimony": Simpler is better.  As Einstein said, "Everything should be made as simple as possible, but not simpler."
    * Interpretability.  Particularly when there are many input variables, it can become burdensome to keep track of all the different terms.  Often, only a few terms are important.
    * Noise.  Measured data inevitably includes noise: random fluctuations that are not part of the overall relationship.  Techniques from statistics provide a formal way to decide when a model term is mainly shaped by noise and not the relationship you are modeling.  


To give you something to work with, here are three "relationships" $f(x,y)$, $g(x,y)$, and $h(x,y)$.  

```{r }
f = rfun( ~x|y, seed=801 )
g = rfun( ~x|y, seed=802 )
h = rfun( ~x|y, seed=805 )
```
 

```{r ffun,echo=FALSE, out.width="30%", warning=FALSE, message=FALSE, fig.show="hold"}
graphFun( f(x,y)~x|y, 
               xlim=range(-3,3), ylim=range(-3,3)) %>%
  gf_labs(title  = "f(x,y)")

graphFun( g(x,y)~x|y, 
          xlim=range(-3,3), ylim=range(-3,3)) %>%
  gf_labs(title  = "g(x,y)")

graphFun( h(x,y)~x|y, 
          xlim=range(-3,3), ylim=range(-3,3)) %>%
  gf_labs(title  = "h(x,y)")
```
 
You are going to use these to experiment with making polynomial approximations in first- and second-order.  Each of these functions is somewhat complicated, with many ups and downs: a landscape, as it were.  The first- and second-order polynomials are well suited to model **a small portion** of the complicated landscape.  As it happens, those small, simplified landscapes are pretty useful in modeling relationships in the real world.

In each of the following cases, you will use `m2Fit` to fit a local polynomial to the landscape feature of interest.   Your command will look like this:
```{r eval = FALSE, echo=FALSE}
Sample <- expand.grid(
  x = seq(1, 3, length = 50),
  y = seq(0.5, 1.5, length = 50)
) %>% 
  mutate(value = f(x, y))

f_approx <- 
  fitModel(value ~ a + b*x + c*y + d*x*y,
           data = Sample)
```
 

#. Set the center of the "approximation circle" over the feature   and set the radius of the circle to 1.0.
#. Play with including and excluding the various polynomial terms.   Examine both the RMS error and how well the shape of the   approximation matches the landscape of the actual function.
#. Decide which terms you think are essential and which can be   excluded.  Circle the essential terms.  

Your choice of ``essential terms" will be subjective.  Formal methods for making such a selection are introduced in statistical modeling courses.


#. An east-west hillside.  Function $f(x,y)$ at $(x=-2, y=0)$.  
  
Circle the "essential" terms: $x$, $y$, $x y$, $x^2$, $y^2$

#. A NW-SE hillside.  Function $f(x,y)$ at $(x=2, y=-1)$.  
  
Circle the "essential" terms: $x$, $y$, $x y$, $x^2$, $y^2$

#. An amphitheater.  Function $f(x,y)$ at $(x=-1, y=3)$.
  
Circle the "essential" terms: $x$, $y$, $x y$, $x^2$, $y^2$

#. A bowl.  Function $f(x,y)$ at $(x=-0.75, y=-2)$.

Circle the "essential" terms: $x$, $y$, $x y$, $x^2$, $y^2$

#. A mountain.  Function $g(x,y)$ at $(x=0,y=0)$.
  
Circle the "essential" terms: $x$, $y$, $x y$, $x^2$, $y^2$

#. A saddle.  Function $h(x,y)$ at $(x=-1,y=1)$.

Circle the "essential" terms: $x$, $y$, $x y$, $x^2$, $y^2$

Extra Credit:  

#. Make the radius of the approximation circle very large.  Looking at how well the shape of the approximation matches the underlying function, what happens?  
#. Now make the radius of approximation very small, say $0.3$.  Does this make it easier to match the underlying function (over the approximation region) with fewer terms?  
#. Does the answer to (B) depend on the type of landscape feature being approximated?

# Exercise 11

The figure depicts the effect of a drug on heart rate. The effect depends both on the dose of the drug and on the age of the person taking the drug.

```{r drugdose, eval=FALSE, echo = FALSE}
graph.paper( yticks = seq(50,90,by=10), xticks=seq(200,300,by=25),
            xlab="Drug Dose (mg)", ylab="Heart Rate (bpm - beats per minute)")
curve( 0.2*(x-175) + 60, add=TRUE,col="red",lwd=2)
curve( 0.0*(x-200) + 70, add=TRUE,col="blue",lwd=2)
curve( -0.2*(x-175) + 80, add=TRUE,lwd=2)
text(300,53,"Age 20",pos=2,srt=-25)
text(300,87,"Age 40",pos=2,srt=25,col="red")
text(285,70,"Age 30",pos=3,col="blue")
```
 
```{r echo=FALSE}
knitr::include_graphics("/images/HRdrug-drugdose.png")
```

Using the information shown in the graph, estimate numerically each of the following partial derivatives, giving proper units for each. (Heart rate is measured in ``bpm" (beats per minute) and dose in ``mg".)

1. The derivative $\frac{\partial}{\partial \mbox{dose}} HR$.
    
    a. at dose$=275$, age  $= 20$.
    #. at dose$=275$, age  $= 30$.
    #. at dose$=275$, age  $= 40$.
     
#. $\frac{\partial}{\partial \mbox{age}} HR$ at dose$=275$, age $= 30$.

#. $\frac{\partial}{\partial \mbox{dose}} \frac{\partial}{\partial \mbox{dose}} HR$ at dose$=275$, age $= 30$.

#. $\frac{\partial}{\partial \mbox{age}} \frac{\partial}{\partial \mbox{age}} HR$ at dose$=275$, age $= 30$.

#. $\frac{\partial}{\partial \mbox{age}} \frac{\partial}{\partial \mbox{dose}} HR$ at dose$=275$, age $= 30$.

# Exercise 12

Here's a contour diagram showing the depth of a lake and the landscape around it.  **Negative values** are underwater. 

```{r one, eval=FALSE, echo = FALSE}
f = practice.max( seed=78344 )
ff = function(x,y){-5*(f(x/100, y/100)-3)}
contour.plot(ff, xlim=c(-700,700), ylim=c(-700,700), xlab="", ylab="", filled=FALSE,
             levels=c(-20,-15,-10,-5,5,10,15),las=2)
contour.plot(ff, levels=0, lwd=4, filled=FALSE,add=TRUE)
#x = c(3.2,4,-1,-3,-1.5)
#y = c(1,3.5,-4, 1.5,-2)
#points(x,y, pch=20, cex=2)
#text(x,y,c("M","N","O","P","S"),pos=4)
```

```{r echo=FALSE}
knitr::include_graphics("/images/lake-one.png")
```

The axis scales and contour units are in feet.

For each of the following, mark on the graph a location where   the conditions apply.  Make sure to use the letters, A -- D to   distinguish the various points from one another.

1. The lake bottom is **steep** and fairly **deep**.
#. The lake bottom is **steep** and **shallow**.
#. The lake bottom is **relatively flat** and **deep**.
#. The lake bottom is **relatively flat** and **shallow**.

# Exercise 13

The graphs on the left side of the table give some function $f(x,y)$. For each of the graphs, say whether the graph on the right side of the table gives $\frac{\partial f}{\partial x}$ or $\frac{\partial   f}{\partial y}$.  (You just need to write down which one it is, not do any detailed calculation.)


$f( x, y )$ |  Is it $\frac{\partial f}{\partial x}$ or $\frac{\partial f}{\partial y}$
------------|-------------
![](/images/p502-f1.png} | ![](/images/p502-df1.png} 
![](/images/p502-f2.png} | ![](/images/p502-df2.png} 

# Exercise 14

```{r echo=FALSE}
knitr::include_graphics("/images/p501-fz.png")
```

1. Estimate a number for the derivative of the function $f(x,y)$ at the indicated point:

    a. $\frac{\partial f}{\partial x}$ at A.
    #. $\frac{\partial f}{\partial x}$ at B.
    #. $\frac{\partial f}{\partial y}$ at A.
    #. $\frac{\partial f}{\partial y}$ at B.

#. Mark a point on the graph where both  $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ are very small in magnitude. Label the point with "small."
#. Mark a point on the graph where both  $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ are very big in magnitude. Label the point with "big."
 
# Exercise 15

World population, in billions

```{r echo=FALSE}
Table <- tribble(
  ~ year, ~ population,
  1975, 4.08,
  1980, 4.45,
  1985, 4.84,
  1990, 5.27,
  1995, 5.68,
  2000, 6.07,
  2005, 6.45
)
SDSdata::sds_table(Table, show_n = Inf)
```
#. What are the units of average rate of change for the data below?
    a. Years
    #. Billions of people
    #. *Billions of people per year*
    #. Years per billions of people
    #. Years $\times$ billions of people
    
#. Using the data, find the average rate of change in the world's population between 1975 and 2005.
    a. $6.45/2005$
    #. $4.08/1975$
    #. $1975/4.08$
    #. $2005/6.45$
    #. $\frac{4.08 - 6.45}{2005-1975}$
    #. *$\frac{6.45 - 4.08}{2005-1975}$*
    #. $\frac{2005-1975}{4.08 - 6.45}$
    #. $\frac{2005-1975}{6.45 - 4.08}$

#. Which is the best estimate of the derivative of the population curve in $2005$?
     a. $2005/6.45$
     #. $6.45/2005$
     #. *$0.38/5$*
     #. $2.37/30$
     
# Exercise 16

The figure shows a model of farming population as a  function of year:

```{r echo=FALSE}
f <- makeFun(20 + 2000*dnorm(year, mean = 1931, sd =  20) ~ year)
graphFun(f(year) ~  year, yearlim = c(1925, 2015)) %>%
  gf_labs(y = "f(t)")
```
1. If $f^\prime(1950) < 0$, what does this tell you about the farming population in 1950?

    a. The number of farms reached a peak in 1950.
    #. The number of farms is going up in 1950.
    #. *The number of farms is going down 1950.*
    
2. Which of these statements is true?

    a. $f^\prime(1950) > f^\prime(1970)$.
    #. $f^\prime(1950) > f^\prime(1970)$.
    #. *$f^\prime(1950) < f^\prime(1970)$.*
    #. *The number of farms is going down 1950.*
    
# Exercise 12

Consider the following function ...

```{r echo=FALSE}
set.seed(101)
pts <- data_frame(x = -5 +  cumsum(0.5 + rexp(7) ), y = runif(7))
refx <- sort(c(-3.7, -1.66, -0.5, 1.4, 3.62, 1.075, 2.47 ))
f <- spliner(y ~ x, data =  pts)
special_pts <- data_frame(x = refx, y = 8 * f(refx) - 3)
label <- character(8)
special_pts$label = 
  sapply(1:length(refx),
        FUN = function(x) paste0("x", x))
gf_fun(8*f(x)-3 ~ x, xlim = c(-4, 4)) %>%
  gf_labs(y = "f(x)") %>%
  gf_point(y ~ x, data = special_pts) %>%
  gf_segment(3 + y ~ x + x, data = special_pts, linetype = 2)  %>%
  gf_label(3 ~ x, label = ~ label, data = special_pts )
```

1. At which point is $f(x)$ at a global minimum? {$x_3$, *$x_2$*, $x_6$, none of them}
#. At which point is $f(x)$ at a local maximum? {$x_1$, $x_2$, *$x_4$*, $x_7$, none of them}
#. At which point is the derivative (with respect to $x$) the smallest? {*$x_1$*, $x_3$, $x_5$, $x_7$}
#. At which point is the derivative (with respect to $x$) negative? {*$x_1$*, $x_2$, $x_3$, $x_4$, none of them}
#. At which point is the derivative zero? {$x_5$, *$x_6$*, $x_7$, none of them}
#. At which point is the function value zero? {$x_4$, *$x_5$*, $x_6$, none of them}

# Exercise 16

Let $P(t)$ represent the price of a share of stock of a corporation at time $t$.  

1. Consider the statement "the price of the stock today is rising faster and faster." The first and second derivative of $P(t)$ today are, respectively,
    a. $-,\ -$
    #. $-,\ 0$
    #. $-,\ +$
    #. $0,\ -$
    #. $0,\ 0$
    #. $0,\ +$
    #. $+,\ -$
    #. $+,\ 0$
    #. *$+,\ +$*
    
#. Consider the statement "the price of the stock bottomed out last Thursday." The first and second derivative of $P(t)$ last Thursday are, respectively,
    a. $-,\ -$
    #. $-,\ 0$
    #. $-,\ +$
    #. $0,\ -$
    #. $0,\ 0$
    #. *$0,\ +$*
    #. $+,\ -$
    #. $+,\ 0$
    #. $+,\ +$

# Exercise 14

Each of the graphs shows the position $x$ of a particle -- I, II,  III, or IV -- as a function of time.

```{r echo=FALSE, out.width = "50%", fig.show="hold"}
gf_fun(t^2 - 3 ~ t, xlim=c(0,3)) %>% 
  gf_labs(title = "Particle I", x="time", y = "position")
gf_fun(sin(2*pi*t/3) - 3 ~ t, xlim=c(0,3)) %>% 
  gf_labs(title = "Particle II", x="time", y = "position")
gf_fun(2 - t/1.5 ~ t, xlim=c(0,3)) %>% 
  gf_labs(title = "Particle III", x="time", y = "position")
gf_fun(sqrt(t) ~ t, xlim=c(0,3)) %>% 
  gf_labs(title = "Particle IV", x="time", y = "position")
```

Note that the vertical scales vary from one graph to another. It may be important to take this into account when answering the following.

1. Which graph shows the particle with constant velocity? {I, II, *III*, IV}
#. Which graph shows the particle with the greatest initial velocity? {I, II, III, *IV*}
#. Which graph shows the particle with positive acceleration throughout?{I, II, III, IV}
#. Which graph shows the particle with zero average velocity?{I, *II*, III, IV}
#. Which graph shows the particle with the greatest average velocity? {*I*, II, III, IV}
#. Which graph shows the particle with zero acceleration? {I, II, *III*, IV}




# Exercise 15

```{r echo=FALSE}
set.seed(133)
pts <- data_frame(x = -5 +  cumsum(0.5 + rexp(5) ), y = runif(5))
refx <- sort(c(-3.7, -2.4, -0.95, 3.62,  2.47 ))
f <- spliner(y ~ x, data =  pts)
special_pts <- data_frame(x = refx, y = 8 * f(refx) - 3)
label <- character(8)
special_pts$label = 
  sapply(1:length(refx),
        FUN = function(x) paste0("x", x))
gf_fun(8*f(x)-3 ~ x, xlim = c(-4, 4)) %>%
  gf_labs(y = "f(x)") %>%
  
  gf_point(y ~ x, data = special_pts) %>%
  gf_segment(15 + y ~ x + x, data = special_pts, linetype = 2)  %>%
  gf_label(15 ~ x, label = ~ label, data = special_pts )
```

1. At which point is the first derivative positive and the second derivative positive as well? {$x_1$, $x_2$, $x_3$, *$x_4$*, none}
#. At which point is the first derivative *negative* and the second derivative positive? {$x_1$, $x_2$, $x_3$, $x_4$, *none*}
#. At which point is the first derivative positive and the second derivative negative? {*$x_1$*, $x_2$, $x_3$, $x_4$, none}
#. At which point is the first derivative negative and the second derivative negative as well? {$x_1$, *$x_2$*, $x_3$, $x_4$, none}
#. At which point is the second derivative closest to zero?  {$x_1$, $x_2$, *$x_3$*, $x_4$}

# Cost and revenue

The graph comes from the classical economics of the theory of the firm. It compares the total cost of producing a quantity $q$ of a product to the total revenue generated by selling that quantity on the market.

```{r echo = FALSE}
data <- tribble(
  ~ quantity, ~ money, ~ which, ~label,
  5,  5*130/25, "revenue", NA,
  25, 130, "revenue", "R",
  5, 60, "cost", NA,
  25, 100, "cost", "C"
)
gf_line(money ~ quantity , color = ~ which, data = data) %>%
  gf_lims(x = c(0,30)) %>%
  gf_text(money ~ quantity, label = ~label, color = "black", xnudge=3)
```

a. At which quantity is the company losing money? {*10*, 16, 20}
#. At quantity = 10, which is greater: the marginal cost of production or the marginal revenue from sales? {marginal cost, *marginal revenue*, they are the same}
#. At quantity = 16, which is greater: the marginal cost of production or the marginal revenue from sales? {marginal cost, *marginal revenue*, they are the same}
#. Assuming that all the sales are made at the same price (or, more precisely, net revenue), what is the price of one unit? Choose the closest. {$2 per unit, *$4 per unit*, $6 per unit }

# Exercise 18: The gradient tells you about change

For a function $f(x,y)$, we are given $f(100,20) = 2750$ and $f_x(100,20) = 4$, and $f_y(100,20) = 7$.  Estimate $f(105,21)$.}

a. $2750 + 4 + 7$
#. $5\times 4 + 1 \times 7$
#. $5\times 7 + 1 \times 4$
#. *$2750 + 5\times 4 + 1 \times 7$*
#. $2750 + 5\times 7 + 1 \times 4$

## Exercise 19: Mortgage costs

For almost everyone, a house is too expensive to buy with cash, so people need to borrow money. The usual form of the loan is called a "mortgage".  Mortgages extend over many years and involve paying a fixed amount each month.  That amount is calculated so that, by paying it each month for the duration of the mortgage, the last payment will completely repay the amount borrowed plus the accumulated interest.

The monthly mortgage payment in dollars, $P$, for a house is a function of three variables, $P = f(A, r, N)$, where $A$ is the amount borrowed in dollars, $r$ is the interest rate (per year), and $N$ is the number of years before the mortgage is paid off. 

A studio apartment is selling for $220,000. You will need to borrow $184,000 to make the purchase. 

#. Suppose $f(184000,14,30) = 2180.16$.  What does this tell you in financial terms?
    a. The monthly cost of borrowing $184,000 for 14 years at 30% interest per year.
    #. *The monthly cost of borrowing $184,000 for 30 years at 14% interest per year.*

#. What would you expect about the quantity $\partial P / \partial A$?

    a. *Positive*
    #. Negative
    #. Zero

#. What would you expect about the quantity $\partial P / \partial N$?

    a. Positive
    #. *Negative*
    #. Zero

#. Suppose $\partial P / \partial r (184000,14,30) = $145.64.  What is the financial significance of the number $145.65?

    a. If the interest rate $r$ went up from 14 to 15, the monthly payment would increase by $145.65.
    #. If the interest rate $r$ went up from 14 to 14.001, the monthly payment would increase by $145.65.
    #. *If the interest rate $r$ went up from 14 to 14.001, the monthly payment would increase by $0.001 \times $145.65.*
    
# Exercise 37

Consider the contour diagram shown below of a function $U = f(x, y)$. Say whether each of the given derivatives, at the point $(4, 4)$,  appears to be positive, negative, or zero.

```{r cplot, echo = FALSE}
f = function(x,y){  }
graphFun( 10*(y+1)/(x+1) ~ x + y, 
          xlim=c(0,10), ylim=c(0,10), tile=FALSE) %>% gf_labs(
          levels=c(5,10,15,20,25,30,35,40)) 
```
 
1. $\partial U/\partial x$ 
#. $\partial U/\partial y$
#. $\partial^2 U/\partial x^2$
#. $\partial^2 U/\partial y^2$
#. $\partial^2 U/ (\partial x \partial y)$

# Exercise 38

When constructing a partial derivative, remember this: other than the variable with respect to which differentiation is being taken,  *all other variables* are treated as constants.  This is just a little bit different than ordinary differentiation, where the other variables may well themselves vary with the variable of differentiation.  The fact that a variable is called $y$ doesn't mean that $y$ might not change with $x$.  But when taking a partial derivative $\partial / \partial x$, the variable $y$ will be held constant even as $x$ changes. 

The following examples illustrate this rule.  Make sure you understand them:




Ordinary Derivatives | | Partial Derivatives
----------------|--------|-----------
$\frac{d}{dx} y = \frac{dy}{dx}$  | but |   $\frac{\partial}{\partial x} y = 0$ 
$\frac{d}{dx} x y = y + x \frac{dy}{dx}$  | but |   $\frac{\partial}{\partial x} x y = y$ 
$\frac{d}{dx} \left( x +  y\right) = 1 + \frac{dy}{dx}$  | but |   
$\frac{\partial}{\partial x} \left( x + y \right) = 1$
$\frac{d}{dx} \left( x^2 +  y^2\right) = 2x + 2y\frac{dy}{dx}$  | but |   $\frac{\partial}{\partial x}\left( x^2 + y^2\right) = 2x$. 
\end{tabular}}



Find the following derivatives, being careful to distinguish *partial* derivatives ($\partial$) from ordinary derivatives ($d$).  Following convention, $x$, $y$, $z$, and $t$ represent variables, $a$, $b$, $c$, $a_0$, $a_1$, $b_0$, $b_1$, $\ldots$ are constants, and $f$, $g$ and $h$ are functions.  When the particular form of a function isn't stated, you can write the ordinary derivative (of a function of one variable) as $f'$, $g'$, or $h'$ respectively.  The partial  derivative with respect to $x$ can be written $f_x$, $g_x$, or $h_x$.

Find the symbolic derivatives of these expressions. Pay careful attention to the variable of differentiation; it changes from problem to problem.  Note that some of the problems involve ordinary differentiation, others involve partial differentiation.

1. $\frac{\partial}{\partial x} x$
#. $\frac{\partial}{\partial x} y$
#. $\frac{d}{d x} a x $
#. $\frac{\partial}{\partial x} x y$
#. $\frac{d}{d x} x y$
#. $\frac{\partial}{\partial y} x y$
#. $\frac{d}{d y} x y$
#. $\frac{d}{d y} x y$
#. $\frac{\partial}{\partial x} A e^{kt}$
#. $\frac{\partial}{\partial t} A e^{kt}$
#. $\frac{\partial}{\partial x} A x e^{kt}$
#. $\frac{\partial}{\partial t} A x e^{kt}$
#. $\frac{\partial}{\partial x} \left( a_0 + a_1 x + a_2 x^2\right)$
#. $\frac{\partial}{\partial y} \left( a_0 + a_1 x + a_2 x^2\right)$
#. $\frac{\partial}{\partial x} \left( b_0 + b_1 y + b_2 y^2\right)$
#. $\frac{\partial}{\partial y} \left( a_0 + a_1 x + b_1 y\right)$
#. $\frac{\partial}{\partial x} \left( a_0 + a_1 x + b_1 y\right)$
#. $\frac{\partial}{\partial x} \left( a_0 + a_1 x + b_1 y + c x y\right)$
#. $\frac{\partial}{\partial y} \left( a_0 + a_1 x + b_1 y + c x y\right)$
#. $\frac{\partial}{\partial y} \left( a_0 + a_1 x + b_1 y + c x y + a_2 x^2 + b_2 y^2\right)$
#. $\frac{\partial}{\partial x} \left( a_0 + a_1 x + b_1 y + c x y + a_2 x^2 + b_2 y^2\right)$
#. $\frac{\partial}{\partial x} A x^n y^m$
#. $\frac{\partial}{\partial y} A x^n y^m$
#. $\frac{\partial}{\partial x} \left( f(x) + y \right)$
#. $\frac{d}{dx} \left( f(x) + y \right)$
#. $\frac{d}{dx} \left( f(x+y)  \right)$
#. $\frac{\partial}{\partial x} \left( f(x) + g(y) \right)$
#. $\frac{\partial}{\partial y} \left( f(x) + g(y) \right)$
#. $\frac{d}{dx} \left( f(x) + g(y) \right)$
#. $\frac{\partial}{\partial x} f(x) g(y)$
#. $\frac{\partial}{\partial y} f(x) g(y)$
#. $\frac{d}{dx} f(x) g(y)$
#. $\frac{\partial}{\partial x} h(x,y) g(y)$
#. $\frac{\partial}{\partial y} h(x,y) g(y)$
#. $\frac{\partial}{\partial x} f(x) h(x,y) g(y)$
#. $\frac{\partial}{\partial y} f(x) h(x,y) g(y)$

# Exercise 39: Derivatives of Modeling Functions

Find each of these derivatives:

1. $\frac{d}{dt} \cos( \frac{2 \pi}{P} t )$
#. $\frac{d}{dt} \cos( a t )$
#. $\frac{d}{dt} \cos( t / T )$
#. $\frac{d}{dx} \ln(1+x)$
#. $\frac{d}{dx} \ln(1+a x)$
#. $\frac{d}{dx} \ln(b+a x)$
#. $\frac{d}{dt} e^{kt}$
#. $\frac{d}{dt} e^{t/T}$
#. $\frac{d}{dt} e^{kt} \cos(\frac{2 \pi}{P} t)$
#. Watch out! $\frac{d}{dx} \cos( a t )$  
#. $\frac{d}{dt} 2^{t/T}$
#. $\frac{d}{dt} (1+r)^{t}$
#. Watch out! $\frac{d}{dr} (1+r)^{t}$


# Exercise 40: Commit to memory

Here is a table of the derivatives and anti-derivatives of the basic modeling functions.  To make the forms as simple as possible, the functions have been written without parameters.  Of course, in actual practice, to use these functions for modeling you would need to write them with their appropriate parameters.  This table merely highlights one aspect of the patterns of derivatives.


  | Anti-Derivative | Function | Derivative
:---|:----:|:----:|:----: 
Name convention | F | f | f'
Operator notation  | $\int f(x) dx$ | $f(x)$ | $\frac{df}{dx}$
Basic Modeling | Functions  | 
Power Law | $\frac{1}{n+1} x^{n+1}$ | $x^n$ | $n x^{n-1}$
Sine | $-\cos(x)$ | $\sin(x)$ | $\cos(x)$
Cosine | $\sin(x)$ | $\cos(x)$ | $-\sin(x)$
Log | $x \ln(x) - x$ | $\ln(x)$ | $1/x$
Exponential | $e^x$ | $e^x$ | $e^x$


By memorizing the table, you will be able to reserve your intellectual capabilities for problems that matter, rather than struggling to derive routine facts.

1. After you've memorized the table above, fill in this version without referring to the original

  | Anti-Derivative | Function | Derivative
:---|:----:|:----:|:----:
Name convention | |  | 
Operator notation  | |
Basic Modeling | Functions
Power Law |  | |
Sine |  | | 
Cosine |  | | 
Log |  | |
Exponential |  | | 

#. Do it again!  But don't turn the sheet over to look.

  | Anti-Derivative | Function | Derivative
:---|:----:|:----:|:----:
Name convention | |  | 
Operator notation  | |
Basic Modeling Functions |
Power Law |  | |
Sine |  | | 
Cosine |  | | 
Log |  | |
Exponential |  | | 

#. Using the relationships shown in the "Function" and "Derivative" columns, show that differentiating the expression in the Anti-Derivative column leads to the expression in the Function column.  To differentiate the Anti-Derivative of the log function, you will need to use the product rule: $f(x) g(x) \rightarrow f'(x) g(x) + f(x) g'(x)$.

# Exercise 41

One of the important techniques for computing a derivative involves symbolic manipulation.  This is not usually a process that involves deep thought, but rather one that calls for good pattern recognition skills and the systematic application of a small set of rules.  There are some symbolic arithmetic problems that everybody should be able to do fluently and others that, while doable, are so involved that there is a substantial risk of making a mistake.  The situation is quite similar to that of arithmetic.  All numerically literate people should be able easily to solve problems like $3 + 9$ or $15/3$ or $7\times 2$.  Most people, even quite literate ones, cannot easily do similar problems such as $3592.35 + 5823.28$ or $15.32 / 2.87$.

"Basic problems" are ones you should be able to do fluently without much thought.  Some examples:


1. $\frac{d}{dx} x$

    a. $0$
    #. *$1$*
    #. $x$
    #. $x^2$


#. $\frac{d}{dx} k$

    a. *$0$*
    #. $1$
    #. $x$
    #. $x^2$


#. $\frac{d}{dx} k$

   a. *$0$*
   #. $1$
   #. $k$
   #. $kx$


#. $\frac{d}{dx} k x$

    a. $0$
    #. $1$
    #. *$k$*
    #. $kx$


#. $\frac{d}{dx} k x^2$

     a. $0$
     #. $k$
     #. $2 k$
     #. $kx$
     #. *$2 k x$*


#. $\frac{\partial}{\partial t} k x^2$ (Note the differentiation with respect to $t$.)

     a. *$0$*
     #. $k$
     #. $2 k$
     #. $kx$
     #. $2 k x$


#. $\frac{\partial}{\partial t} k x^2 t$ (Note the differentiation with respect to $t$.)

    a. $0$
    #. $k$
    #. $2 k x$
    #. *$k x^2$*
    #. $2 k x^2$


#. $\frac{\partial}{\partial t} e^t$ 

    a. $0$
    #. $t$
    #. *$e^t$*
    #. $t e^t$


#. $\frac{\partial}{\partial t} k e^t$ 

    a. $0$
    #. $t$
    #. *$k e^t$*
    #. $k e^{k t}$
    #. $t e^k$


#. $\frac{\partial}{\partial t} e^{kt}$ 

   a. $0$
   #. $t$
   #. $k e^t$
   #. *$k e^{k t}$*
   #. $t e^k$


#. $\frac{\partial}{\partial t} (1+r)^t$ 

    a. $(1+r)^t$
    #. *$\log(1+r) \cdot (1+r)^t$*
    #. $(1+r) \cdot (1+r)^t$
    #. $(1+t) \cdot (1+r)^t$


#. $\frac{\partial}{\partial r} (1+r)^t$ (Note that $r$ is the variable of differentiation.)

     a. $(1+r)^t$
     #. *$(1+r)^{t-1}$*
     #. $(1+t) \cdot (1+r)^t$



#. $\frac{\partial}{\partial t} \sin( \frac{2\pi}{P} t )$ 

     a. $\cos( \frac{2 \pi}{P} t$
     #. *$\frac{2 \pi}{P} \cos( \frac{2 \pi}{P} t$*
     #. $\sin( \frac{2 \pi}{P} t$
     #. $\frac{2 \pi}{P} \sin( \frac{2 \pi}{P} t$


#. $\frac{d}{dx} f(a x + b)$  where $\frac{d}{dx} f(x) = f'(x)$.

    a. $f'(a x + b)$
    #. *$a f'(a x + b)$*
    #. $b f'(a x + b)$
    #. $(a+b) f'(a x + b)$


#. $\frac{\partial}{\partial x} a_0 + a_1 x + a_2 y + a_3 x y + a_4 x^2 + a_5 y^2$

    a. $a_1 + 2 a_4 x$
    #. *$a_1 + a_3 y + 2 a_4 x$*
    #. $a_1 + a_3 x + 2 a_4 x$
    #. $a_1 + a_3 x + 2 a_4 x + a_5 y$


#. $\frac{\partial^2}{\partial x^2} a_0 + a_1 x + a_2 y + a_3 x y + a_4 x^2 + a_5 y^2$

    a. $0$
    #. $a_4$
    #. *$2 a_4$*
    #. $2 a_4 + 2 a_5$


#. $\frac{\partial^2}{\partial  y \partial x} a_0 + a_1 x + a_2 y + a_3 x y + a_4 x^2 + a_5 y^2$

    a. $0$
    #. $a_4$
    #. *$a_3$*
    #. $2 a_4 + 2 a_5$



